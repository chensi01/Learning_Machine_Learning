# Naive Bayes
—-

- [X] 学习和分类
- [X] 参数估计

—-

### 1.学习和分类
- 基于贝叶斯定理和条件独立性假设（类标确定的情况下，用于分类的特征是条件独立的）的分类算法
- 输入的训练集合是根据联合概率分布$P(XY)$独立同分布生成的
- 训练时学习联合概率分布（通过类先验概率分布和基于条件独立性假设学习条件概率分布）【由于学习的是生成数据的模式，属于生成模型】
- 预测时，输出后验概率最大的类标（最大化后验概率等价于最小化0-1损失下的期望风险）

—-
### 2.参数估计
1. 极大似然估计
$P(Y=j)=\frac{I(Y=j)}{I}$
$P(x=x_i|Y=j) = \frac{P(x_i=nn|Y=j)}{\sum_n P(x_i=n|Y=j)}$
2. 贝叶斯估计
避免概率为0
条件概率的估计那里分母加$K\lambda$，分子加$\lambda$
lambda=0：极大似然估计估计
Lambda=1：拉普拉斯平滑
—-

reference 李航
